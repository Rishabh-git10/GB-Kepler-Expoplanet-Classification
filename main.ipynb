{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing librabries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an empty dataframe for storing the data after each iteration\n",
    "results_df = pd.DataFrame(columns=['n_estimators', 'learning_rate', 'max_depth', 'max_features', 'mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "file_path = \"./dataset.csv\"\n",
    "try:\n",
    "    dataset = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the path and try again.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify if dataset is a dataframe\n",
    "if not isinstance(dataset, pd.DataFrame):\n",
    "    print(\"Dataset is not a dataframe. Please check the file and try again.\")\n",
    "    exit(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(dataset['koi_disposition'])\n",
    "\n",
    "dataset_numeric = dataset.dropna(subset=['koi_score'])\n",
    "\n",
    "#Save the 'koi_disposition' column in a variable and drop it from the dataset\n",
    "koi_disposition_column = dataset['koi_disposition']\n",
    "\n",
    "non_numeric_columns = dataset.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "#Drop 'koi_disposition' and any other non-numeric columns from the dataset\n",
    "dataset_numeric = dataset.drop(columns=non_numeric_columns)\n",
    "\n",
    "dataset_numeric['koi_disposition'] = koi_disposition_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_numeric.drop(columns=['koi_disposition']), y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values using SimpleImputed for the training and testing sets\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the training and testing sets\n",
    "scaler = StandardScaler().fit(X_train_imputed)\n",
    "X_train_scaled = scaler.transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting initial ranges for hyperparameters\n",
    "param_ranges = {\n",
    "    'n_estimators': (90, 130),\n",
    "    'learning_rate': (0.01, 0.1),\n",
    "    'max_depth': (5, 15),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "#Setting the number of iterations\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
